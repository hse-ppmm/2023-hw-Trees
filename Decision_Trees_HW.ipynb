{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Decision_Trees_HW.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Это домашнее задание поможет попрактиковаться с деревьями решений. Сначала изучите разделы **Деревья классификации** и **Деревья классификации своими руками** из этой тетрадки. Убедитесь, что код во всех ячейках в них вам понятен. Затем выполните два задания, построив модели с *Деревьями регрессии*."
      ],
      "metadata": {
        "id": "SfdHu02JJRen"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFxAmLIq6a1R"
      },
      "source": [
        "Деревья классификации\n",
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmG7lWgx6a1I"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpIdyEA86a1U"
      },
      "source": [
        "np.random.seed(43)\n",
        "\n",
        "n = 250\n",
        "\n",
        "mu1 = np.array([0.0,0])\n",
        "mu2 = np.array([1.0,0])\n",
        "sigma1 = 5.0 * np.diag(np.array([1.0, 1.0]))\n",
        "sigma2 = 0.5 * np.diag(np.array([1.0, 1.0]))\n",
        "\n",
        "x1 = np.random.multivariate_normal(mu1, sigma1, n)\n",
        "x2 = np.random.multivariate_normal(mu2, sigma2, n)\n",
        "x = np.vstack([x1, x2])\n",
        "y = np.concatenate([np.full(x1.shape[0], 0), np.full(x2.shape[0], 1)])\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(*x1.T,s=2.5)\n",
        "plt.scatter(*x2.T,s=2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4so8NGIG6a1X"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFvMxayf6a1a"
      },
      "source": [
        "def flat_dict(x):\n",
        "    if len(x) == 0:\n",
        "        return dict()\n",
        "    return {k: np.asarray([e[k] for e in x]) for k in x[0].keys()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5dq09-56a1c"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "max_depths = np.arange(1, 2 * np.log2(n))\n",
        "\n",
        "scoring = {\n",
        "    \"auc\":       \"roc_auc\",\n",
        "    \"accuracy\":  \"accuracy\",\n",
        "}\n",
        "\n",
        "scores = []\n",
        "for max_depth in max_depths:\n",
        "    c = DecisionTreeClassifier(max_depth=max_depth)\n",
        "    s = cross_validate(c, x, y.reshape(-1), cv=5, scoring=scoring, return_train_score=True)\n",
        "    scores.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkFKrkL76a1e"
      },
      "source": [
        "scores = flat_dict(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST0M0eRW6a1f"
      },
      "source": [
        "plt.plot(max_depths, scores['train_accuracy'].mean(axis=1), '-*', label=\"train accuracy\")\n",
        "plt.plot(max_depths, scores['test_accuracy'].mean(axis=1), '-*', label=\"test accuracy\")\n",
        "plt.xlabel(\"Tree max depth\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "s8tCP8HZ6a1i"
      },
      "source": [
        "x_grid = np.linspace(np.min(x), np.max(x), 2000)\n",
        "xx, yy = np.meshgrid(x_grid, x_grid)\n",
        "xx_test = np.stack((xx,yy), axis=-1).reshape(-1, 2)\n",
        "\n",
        "c = DecisionTreeClassifier(random_state=0, max_depth=15)\n",
        "\n",
        "c.fit(x_train, y_train)\n",
        "pred = c.predict(xx_test).reshape(xx.shape)\n",
        "\n",
        "x1_train = x_train[y_train == 0]\n",
        "x2_train = x_train[y_train == 1]\n",
        "\n",
        "plt.figure()\n",
        "plt.xlim(-2,3)\n",
        "plt.ylim(-2,3)\n",
        "plt.contourf(xx, yy, pred, cmap=\"pink_r\")\n",
        "plt.scatter(*x1_train.T,s=2.5)\n",
        "plt.scatter(*x2_train.T,s=2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60PEXJiL6a1k"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "min_samples_leafs = np.arange(1, 20)\n",
        "\n",
        "scoring = {\n",
        "    \"auc\":       \"roc_auc\",\n",
        "    \"accuracy\":  \"accuracy\",\n",
        "}\n",
        "\n",
        "scores = []\n",
        "for min_samples_leaf in min_samples_leafs:\n",
        "    c = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
        "    s = cross_validate(c, x, y.reshape(-1), cv=5, scoring=scoring, return_train_score=True)\n",
        "    scores.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFRz353F6a1m"
      },
      "source": [
        "scores = flat_dict(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odq8V9q36a1n"
      },
      "source": [
        "plt.plot(min_samples_leafs, scores['train_accuracy'].mean(axis=1), '-*', label=\"train accuracy\")\n",
        "plt.plot(min_samples_leafs, scores['test_accuracy'].mean(axis=1), '-*', label=\"test accuracy\")\n",
        "plt.xlabel(\"Leaf size\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpaAT__k6a1o"
      },
      "source": [
        "c = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "path = c.cost_complexity_pruning_path(x_train, y_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcBWPoT46a1p"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
        "ax.set_xlabel(\"Effective alpha\")\n",
        "_ = ax.set_ylabel(\"Total impurity of leaves\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmkCY9W6a1q"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scoring = {\n",
        "    \"auc\":       \"roc_auc\",\n",
        "    \"accuracy\":  \"accuracy\",\n",
        "}\n",
        "\n",
        "scores = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    c = DecisionTreeClassifier(ccp_alpha=ccp_alpha)\n",
        "    s = cross_validate(c, x, y.reshape(-1), cv=5, scoring=scoring, return_train_score=True)\n",
        "    scores.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G94k27HU6a1r"
      },
      "source": [
        "scores = flat_dict(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqovB74e6a1s"
      },
      "source": [
        "plt.plot(ccp_alphas, scores['train_accuracy'].mean(axis=1), '-*', label=\"train accuracy\")\n",
        "plt.plot(ccp_alphas, scores['test_accuracy'].mean(axis=1), '-*', label=\"test accuracy\")\n",
        "plt.xlabel(\"CCP alpha\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K8jGbWg6a1t"
      },
      "source": [
        "Деревья классификации своими руками\n",
        "-----------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-I5e_IE6a1u"
      },
      "source": [
        "from collections import namedtuple\n",
        "from scipy import optimize\n",
        "\n",
        "Leaf = namedtuple('Leaf', ('value', 'x', 'y'))\n",
        "Node = namedtuple('Node', ('feature', 'value', 'impurity', 'left', 'right',))\n",
        "\n",
        "class BaseDecisionTree:\n",
        "    def __init__(self, x, y, max_depth=np.inf):\n",
        "        self.x = np.atleast_2d(x)\n",
        "        self.y = np.atleast_1d(y)\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "        self.features = x.shape[1]\n",
        "        \n",
        "        self.root = self.build_tree(self.x, self.y)\n",
        "    \n",
        "    # Will fail in case of depth ~ 1000 because of limit of recursion calls\n",
        "    def build_tree(self, x, y, depth=1):\n",
        "        if depth > self.max_depth or self.criteria(y) < 1e-6:\n",
        "            return Leaf(self.leaf_value(y), x, y)\n",
        "        \n",
        "        feature, value, impurity = self.find_best_split(x, y)\n",
        "        \n",
        "        left_xy, right_xy = self.partition(x, y, feature, value)\n",
        "        left = self.build_tree(*left_xy, depth=depth + 1)\n",
        "        right = self.build_tree(*right_xy, depth=depth + 1)\n",
        "        \n",
        "        return Node(feature, value, impurity, left, right)\n",
        "    \n",
        "    def leaf_value(self, y):\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    def partition(self, x, y, feature, value):\n",
        "        i = x[:, feature] >= value\n",
        "        j = np.logical_not(i)\n",
        "        return (x[j], y[j]), (x[i], y[i])\n",
        "    \n",
        "    def _impurity_partition(self, value, feature, x, y):\n",
        "        (_, left), (_, right) = self.partition(x, y, feature, value)\n",
        "        return self.impurity(left, right)\n",
        "    \n",
        "    def find_best_split(self, x, y):\n",
        "        best_feature, best_value, best_impurity = 0, x[0,0], np.inf\n",
        "        for feature in range(self.features):\n",
        "            if x.shape[0] > 2:\n",
        "                x_interval = np.sort(x[:,feature])\n",
        "                res = optimize.minimize_scalar(\n",
        "                    self._impurity_partition, \n",
        "                    args=(feature, x, y),\n",
        "                    bounds=(x_interval[1], x_interval[-1]),\n",
        "                    method='Bounded',\n",
        "                )\n",
        "                assert res.success\n",
        "                value = res.x\n",
        "                impurity = res.fun\n",
        "            else:\n",
        "                value = np.max(x[:,feature])\n",
        "                impurity = self._impurity_partition(value, feature, x, y)\n",
        "            if impurity < best_impurity:\n",
        "                best_feature, best_value, best_impurity = feature, value, impurity\n",
        "        return best_feature, best_value, best_impurity\n",
        "    \n",
        "    # Can be optimized for given .criteria()\n",
        "    def impurity(self, left, right):\n",
        "        h_l = self.criteria(left)\n",
        "        h_r = self.criteria(right)\n",
        "        return (left.size * h_l + right.size * h_r) / (left.size + right.size)\n",
        "    \n",
        "    def criteria(self, y):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def predict(self, x):\n",
        "        x = np.atleast_2d(x)\n",
        "        y = np.empty(x.shape[0], dtype=self.y.dtype)\n",
        "        for i, row in enumerate(x):\n",
        "            node = self.root\n",
        "            while not isinstance(node, Leaf):\n",
        "                if row[node.feature] >= node.value:\n",
        "                    node = node.right\n",
        "                else:\n",
        "                    node = node.left\n",
        "            y[i] = node.value\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFnIxCgv6a1v"
      },
      "source": [
        "class MyDecisionTreeClassifier(BaseDecisionTree):\n",
        "    def __init__(self, x, y, *args, random_state=None, **kwargs):\n",
        "        y = np.asarray(y, dtype=int)\n",
        "        self.random_state = np.random.RandomState(random_state)\n",
        "        self.classes = np.unique(y)\n",
        "        super().__init__(x, y, *args, **kwargs)\n",
        "        \n",
        "    def leaf_value(self, y):\n",
        "        class_counts = np.sum(y == self.classes.reshape(-1,1), axis=1)\n",
        "        m = np.max(class_counts)\n",
        "        most_common = self.classes[class_counts == m]\n",
        "        if most_common.size == 1:\n",
        "            return most_common[0]\n",
        "        return self.random_state.choice(most_common)\n",
        "    \n",
        "    def criteria(self, y):\n",
        "        \"\"\"Gini\"\"\"\n",
        "        p = np.sum(y == self.classes.reshape(-1,1), axis=1) / y.size\n",
        "        return np.sum(p * (1 - p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2CbQjZN6a1v"
      },
      "source": [
        "c = MyDecisionTreeClassifier(x_train, y_train, max_depth=5, random_state=0)\n",
        "pred = c.predict(xx_test).reshape(xx.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OXHuyPT6a1v"
      },
      "source": [
        "x1_train = x_train[y_train == 0]\n",
        "x2_train = x_train[y_train == 1]\n",
        "\n",
        "plt.figure()\n",
        "plt.xlim(-2,3)\n",
        "plt.ylim(-2,3)\n",
        "plt.contourf(xx, yy, pred, cmap=\"pink_r\")\n",
        "plt.scatter(*x1_train.T,s=2.5)\n",
        "plt.scatter(*x2_train.T,s=2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBLjmmnE6a1w"
      },
      "source": [
        "# Задание 1\n",
        "Перед вами класс `BaseDecisionTree`. Используйте класс `MyDecisionTreeClassifier` в качестве примера, чтобы самостоятельно сделать простое дерево регрессии `MyDecisionTreeRegressor`.\n",
        "\n",
        "Для задачи регрессии в качестве значения листа уместно взять среднее арифметическое значений всех точек содержащихся в узле, в качестве критерия - среднеквадратичное отклонение.\n",
        "\n",
        "Используя синтетический пример с зависимостью (приведен ниже)\n",
        "$$y = 2 x + 1 + \\epsilon$$\n",
        "удебитесь в работоспособности дерева регрессии, подберите наилучший параметр `max_depth`.\n",
        "\n",
        "*Бонусные баллы* можно получить если реализовать функцию `impurity` более эффективно, упростив формулы для случая регрессии."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGdrhJv06a1w"
      },
      "source": [
        "class MyDecisionTreeRegressor(BaseDecisionTree):\n",
        "    def __init__(self, x, y, *args, random_state=None, **kwargs):\n",
        "        # код потерялся\n",
        "    \n",
        "    def leaf_value(self, y):\n",
        "        # код потерялся\n",
        "    \n",
        "    def criteria(self, y):\n",
        "        # код потерялся"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoqe0OA66a1x"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n = 250\n",
        "x = np.random.uniform(0, 1, size=(n, 1))\n",
        "y = 2 * x[:, 0] + 1\n",
        "y = y + np.random.normal(0, 0.1, size=y.shape)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
        "\n",
        "dtr = MyDecisionTreeRegressor(x_train, y_train, random_state=0)\n",
        "\n",
        "plt.xlabel('true')\n",
        "plt.ylabel('predicted')\n",
        "plt.plot(y_train, dtr.predict(x_train), 'o', label='train')\n",
        "plt.plot(y_test, dtr.predict(x_test), 'o', label='test')\n",
        "plt.legend()\n",
        "\n",
        "train_score = mean_squared_error(y_train, dtr.predict(x_train))\n",
        "test_score = mean_squared_error(y_test, dtr.predict(x_test))\n",
        "\n",
        "print(\"train score = {:.4f}\".format(train_score))\n",
        "print(\"test score = {:.4f}\".format(test_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ3_y_DL6v3g"
      },
      "source": [
        "# Задание 2\n",
        "\n",
        "Воспроизведите регрессию из Задания 1 используя реализацию дерева регрессии `sklearn.tree.DecisionTreeRegressor`. Сравните полученные результаты."
      ]
    }
  ]
}